"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7313],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>g});var o=n(7294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function a(e,t){if(null==e)return{};var n,o,l=function(e,t){if(null==e)return{};var n,o,l={},r=Object.keys(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var i=o.createContext({}),u=function(e){var t=o.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},d=function(e){var t=u(e.components);return o.createElement(i.Provider,{value:t},e.children)},c="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},h=o.forwardRef((function(e,t){var n=e.components,l=e.mdxType,r=e.originalType,i=e.parentName,d=a(e,["components","mdxType","originalType","parentName"]),c=u(n),h=l,g=c["".concat(i,".").concat(h)]||c[h]||p[h]||r;return n?o.createElement(g,s(s({ref:t},d),{},{components:n})):o.createElement(g,s({ref:t},d))}));function g(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=n.length,s=new Array(r);s[0]=h;var a={};for(var i in t)hasOwnProperty.call(t,i)&&(a[i]=t[i]);a.originalType=e,a[c]="string"==typeof e?e:l,s[1]=a;for(var u=2;u<r;u++)s[u]=n[u];return o.createElement.apply(null,s)}return o.createElement.apply(null,n)}h.displayName="MDXCreateElement"},8336:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>a,toc:()=>u});var o=n(7462),l=(n(7294),n(3905));const r={id:"7_Scheduling",title:"Scheduling"},s=void 0,a={unversionedId:"Kubernetes/kubernetes_storage_&_scheduling/7_Scheduling",id:"Kubernetes/kubernetes_storage_&_scheduling/7_Scheduling",title:"Scheduling",description:"Scheduling inside Kubernetes, is the part of the master Node (he has the responsibility for scheduling workload).",source:"@site/docs/Kubernetes/3_kubernetes_storage_&_scheduling/7_Scheduling.md",sourceDirName:"Kubernetes/3_kubernetes_storage_&_scheduling",slug:"/Kubernetes/kubernetes_storage_&_scheduling/7_Scheduling",permalink:"/docs/Kubernetes/kubernetes_storage_&_scheduling/7_Scheduling",draft:!1,editUrl:"https://github.com/j-peguet/portfolio/blob/master/docs/Kubernetes/3_kubernetes_storage_&_scheduling/7_Scheduling.md",tags:[],version:"current",lastUpdatedAt:1676381131,formattedLastUpdatedAt:"Feb 14, 2023",sidebarPosition:7,frontMatter:{id:"7_Scheduling",title:"Scheduling"},sidebar:"docs",previous:{title:"Accessing a Private Container Registry",permalink:"/docs/Kubernetes/kubernetes_storage_&_scheduling/6_Access_to_private_registry"},next:{title:"Control Scheduling",permalink:"/docs/Kubernetes/kubernetes_storage_&_scheduling/8_0_Control_scheduling"}},i={},u=[{value:"Kubernetes has one job...",id:"kubernetes-has-one-job",level:3},{value:"starting Pods on Nodes",id:"starting-pods-on-nodes",level:3},{value:"Scheduling in Kubernetes",id:"scheduling-in-kubernetes",level:2},{value:"The goal of Scheduling",id:"the-goal-of-scheduling",level:2},{value:"Scheduling Process",id:"scheduling-process",level:2},{value:"Node Selection",id:"node-selection",level:2},{value:"Resources Request",id:"resources-request",level:2},{value:"Demo 1",id:"demo-1",level:2},{value:"Demo 2",id:"demo-2",level:2}],d={toc:u},c="wrapper";function p(e){let{components:t,...r}=e;return(0,l.kt)(c,(0,o.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("p",null,"Scheduling inside Kubernetes, is the part of the master Node (he has the responsibility for scheduling workload)."),(0,l.kt)("h3",{id:"kubernetes-has-one-job"},"Kubernetes has one job..."),(0,l.kt)("h3",{id:"starting-pods-on-nodes"},"starting Pods on Nodes"),(0,l.kt)("p",null,"But to so this, a lot of decisions have to be made (enough resources, policies in the cluster)."),(0,l.kt)("h2",{id:"scheduling-in-kubernetes"},"Scheduling in Kubernetes"),(0,l.kt)("p",null,"Scheduler is the process of selecting a node to start a Pod on inside of our Clutser"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Selecting a Node to start a Pod on - one of the core components in the master node"),(0,l.kt)("li",{parentName:"ul"},"kube-scheduler - this is the default scheduler"),(0,l.kt)("li",{parentName:"ul"},"you can create our own scheduler")),(0,l.kt)("h2",{id:"the-goal-of-scheduling"},"The goal of Scheduling"),(0,l.kt)("p",null,"Is find the best, most feasible node in the cluster to run a pod."),(0,l.kt)("p",null,"To make this decisions, he have two things:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Resources - cpu, memory, storage"),(0,l.kt)("li",{parentName:"ul"},"Policy - ex: two Pod on different nodes or zones")),(0,l.kt)("h2",{id:"scheduling-process"},"Scheduling Process"),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"scheduling process",src:n(4950).Z,width:"1606",height:"516"})),(0,l.kt)("h2",{id:"node-selection"},"Node Selection"),(0,l.kt)("p",null,"Let's look more closely on the node selection process."),(0,l.kt)("p",null,"The node selection have 3 phases:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Filetering - remove node that cannot run our pod",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"From all the nodes"),(0,l.kt)("li",{parentName:"ul"},"Apply filters"),(0,l.kt)("li",{parentName:"ul"},"Filtered Nodes"),(0,l.kt)("li",{parentName:"ul"},"Hard constraints - pod spec, node resources, etc..."),(0,l.kt)("li",{parentName:"ul"},"If no node is found, the pod is unscheduable and will fail scheduling"))),(0,l.kt)("li",{parentName:"ul"},"Scoring - process of yielding a list of eligible nodes",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Scoring function - Start from the filtered list"),(0,l.kt)("li",{parentName:"ul"},"Feasible Nodes"),(0,l.kt)("li",{parentName:"ul"},"Policu constraints - image on the node, etc..."),(0,l.kt)("li",{parentName:"ul"},"Find the best node to run our pod"))),(0,l.kt)("li",{parentName:"ul"},"Binding - updating the node name in our pods object",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Selected Nodes List - the highest priority nodes"),(0,l.kt)("li",{parentName:"ul"},"Ties are broken - if they are multiple nodes, a random was selected"),(0,l.kt)("li",{parentName:"ul"},"Update API Object")))),(0,l.kt)("h2",{id:"resources-request"},"Resources Request"),(0,l.kt)("p",null,"Resource are important in the process of shoosing a node"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Setting requests will cause the scheduler to find a Node to fit the workload/Pod",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"requests are guarantees"),(0,l.kt)("li",{parentName:"ul"},"CPU"),(0,l.kt)("li",{parentName:"ul"},"Memory"))),(0,l.kt)("li",{parentName:"ul"},"Allocatable resources per Node"),(0,l.kt)("li",{parentName:"ul"},"Pods that need to be scheduled but there not enough resources available will go Pending")),(0,l.kt)("h2",{id:"demo-1"},"Demo 1"),(0,l.kt)("p",null,"Finding scheduling information"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"#Let's create a deployment with three replicas\nkubectl apply -f deployment.yaml\n\n#Pods spread out evenly across the Nodes due to our scoring functions for selector spread during Scoring.\nkubectl get pods -o wide\n\n#We can look at the Pods events to see the scheduler making its choice\nkubectl describe pods \n\n#If we scale our deployment to 6...\nkubectl scale deployment hello-world --replicas=6\n\n#We can see that the scheduler works to keep load even across the nodes.\nkubectl get pods -o wide\n\n#We can see the nodeName populated for this node\nkubectl get pods hello-world-[tab][tab] -o yaml\n\n#Clean up this demo...and delete its resources\nkubectl delete deployment hello-world\n")),(0,l.kt)("h2",{id:"demo-2"},"Demo 2"),(0,l.kt)("p",null,"Scheduling Pods with resource requests. "),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"#Start a watch, the pods will go from Pending->ContainerCreating->Running\n#Each pod has a 1 core CPU request.\nkubectl get pods --watch &\nkubectl apply -f requests.yaml\n\n#We created three pods, one but one is not starting...\nkubectl get pods -o wide\n\n#Let's scale our deployment to 6 replica.  These pods will stay pending.  Some pod names may be repeated.\nkubectl scale deployment hello-world-requests --replicas=6\n\n#We see that three Pods are pending...why?\nkubectl get pods -o wide\nkubectl get pods -o wide | grep Pending\n\n#Let's look at why the Pod is Pending...check out the Pod's events...\nkubectl describe pods\n\n#Now let's look at the node's Allocations...we've allocated 62% of our CPU...\n#1 User pod using 1 whole CPU, one system Pod using 250 millicores of a CPU and \n#looking at allocatable resources, we have only 2 whole Cores available for use.\n#The next pod coming along wants 1 whole core, and tha'ts not available.\n#The scheduler can't find a place in this cluster to place our workload...is this good or bad?\nkubectl describe node c1-node1\n\n#Clean up after this demo\nkubectl delete deployment hello-world-requests\n\n#stop the watch\nfg\nctrl+c\n")))}p.isMDXComponent=!0},4950:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/scheduling_process-f1e8f998749ef2a055f772fb09810ddd.png"}}]);