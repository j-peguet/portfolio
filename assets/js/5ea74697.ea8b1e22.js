"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[284],{3905:function(e,n,t){t.d(n,{Zo:function(){return c},kt:function(){return m}});var r=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,r,o=function(e,n){if(null==e)return{};var t,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var d=r.createContext({}),s=function(e){var n=r.useContext(d),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},c=function(e){var n=s(e.components);return r.createElement(d.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},p=r.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,d=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),p=s(t),m=o,g=p["".concat(d,".").concat(m)]||p[m]||u[m]||a;return t?r.createElement(g,l(l({ref:n},c),{},{components:t})):r.createElement(g,l({ref:n},c))}));function m(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,l=new Array(a);l[0]=p;var i={};for(var d in n)hasOwnProperty.call(n,d)&&(i[d]=n[d]);i.originalType=e,i.mdxType="string"==typeof e?e:o,l[1]=i;for(var s=2;s<a;s++)l[s]=t[s];return r.createElement.apply(null,l)}return r.createElement.apply(null,t)}p.displayName="MDXCreateElement"},2489:function(e,n,t){t.r(n),t.d(n,{frontMatter:function(){return i},contentTitle:function(){return d},metadata:function(){return s},toc:function(){return c},default:function(){return p}});var r=t(3117),o=t(102),a=(t(7294),t(3905)),l=["components"],i={id:"8_4_Node_Cordining",title:"Node Cordoning"},d=void 0,s={unversionedId:"Kubernetes/kubernetes_storage_&_scheduling/8_4_Node_Cordining",id:"Kubernetes/kubernetes_storage_&_scheduling/8_4_Node_Cordining",title:"Node Cordoning",description:"* Marks a Node as unschedulable",source:"@site/docs/Kubernetes/3_kubernetes_storage_&_scheduling/8_4_Node_Cordining.md",sourceDirName:"Kubernetes/3_kubernetes_storage_&_scheduling",slug:"/Kubernetes/kubernetes_storage_&_scheduling/8_4_Node_Cordining",permalink:"/docs/Kubernetes/kubernetes_storage_&_scheduling/8_4_Node_Cordining",editUrl:"https://github.com/j-peguet/portfolio/blob/master/docs/Kubernetes/3_kubernetes_storage_&_scheduling/8_4_Node_Cordining.md",tags:[],version:"current",frontMatter:{id:"8_4_Node_Cordining",title:"Node Cordoning"},sidebar:"docs",previous:{title:"Taints and Tolerations",permalink:"/docs/Kubernetes/kubernetes_storage_&_scheduling/8_3_Taints_&_Tolerations"},next:{title:"Manually Scheduling a Pod",permalink:"/docs/Kubernetes/kubernetes_storage_&_scheduling/8_5_Manually_Scheduling"}},c=[{value:"Demo",id:"demo",children:[],level:2}],u={toc:c};function p(e){var n=e.components,t=(0,o.Z)(e,l);return(0,a.kt)("wrapper",(0,r.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Marks a Node as unschedulable"),(0,a.kt)("li",{parentName:"ul"},"Prevents new Pods from being scheduled to that Node"),(0,a.kt)("li",{parentName:"ul"},"Does not affect any existing Pods on the Node"),(0,a.kt)("li",{parentName:"ul"},"This is useful as a preparatory step before a Node reboot or maintenance",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"kubectl cordon c1-node2"))),(0,a.kt)("li",{parentName:"ul"},"If you want to gracefully evict your Pods from  Node..., before your maintenance, you'll drain the node to ensure that workload gets scheduled somewhere else in the cluster",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"kubectl drain c1-node2 --ignore-daemonsets")))),(0,a.kt)("h2",{id:"demo"},"Demo"),(0,a.kt)("p",null,"Node Cordoning"),(0,a.kt)("p",null,"Check the file deployment.yaml in the demo of ",(0,a.kt)("a",{parentName:"p",href:"/docs/Kubernetes/kubernetes_storage_&_scheduling/8_3_Taints_&_Tolerations"},"Taints and Tolerations\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"#Let's create a deployment with three replicas\nkubectl apply -f deployment.yaml\n\n#Pods spread out evenly across the nodes\nkubectl get pods -o wide\n\n#Let's cordon c1-node2\nkubectl cordon c1-node2\n\n#That won't evict any pods...\nkubectl get pods -o wide\n\n#But if I scale the deployment\nkubectl scale deployment hello-world --replicas=6\n\n#c1-node2 won't get any new pods...one of the other Nodes will get an extra Pod here.\nkubectl get pods -o wide\n\n#Let's drain (remove) the Pods from c1-node2...\nkubectl drain c1-node2 \n\n#Let's try that again since daemonsets aren't scheduled we need to work around them.\nkubectl drain c1-node2 --ignore-daemonsets\n\n#Now all the workload is on c1-node1 and 2\nkubectl get pods -o wide\n\n#We can uncordon c1-node2, but nothing will get scheduled there until there's an event like a scaling operation or an eviction.\n#Something that will cause pods to get created\nkubectl uncordon c1-node2\n\n#So let's scale that Deployment and see where they get scheduled...\nkubectl scale deployment hello-world --replicas=9\n\n#All three get scheduled to the cordoned node\nkubectl get pods -o wide\n\n#Clean up this demo...\nkubectl delete deployment hello-world\n")))}p.isMDXComponent=!0}}]);